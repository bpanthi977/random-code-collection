{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75a24fb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from https://gymnasium.farama.org/tutorials/training_agents/reinforce_invpend_gym_v26/\n",
    "import gymnasium as gym\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d64c56",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# env = gym.make(\"CartPole-v1\", render_mode='human')\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "#%load_ext tensorboard\n",
    "#wandb.init(project=\"cartpole-v1\", entity=\"bpanthi977\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67dd8dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(agent, steps=100):\n",
    "    observation, info = env.reset()\n",
    "    total_reward = 0\n",
    "    total_episodes = 0\n",
    "    for _ in range(steps):\n",
    "        action = agent.action(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        # env.render()\n",
    "        if terminated or truncated:\n",
    "            observation, info = env.reset()\n",
    "            total_episodes += 1\n",
    "            \n",
    "    return total_reward/total_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2040aeb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CartPoleAgent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CartPoleAgent, self).__init__()\n",
    "        input_dim = 4\n",
    "        out_dim = 2\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=input_dim, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=out_dim),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def action(self, state):\n",
    "        probs = self.forward(torch.tensor(state).to(device))\n",
    "        action = np.random.choice([0,1], p=probs.detach().cpu().numpy())\n",
    "        self.action_probs = probs\n",
    "        \n",
    "        return action\n",
    "\n",
    "device = torch.device('mps')   \n",
    "def reset_network():\n",
    "    global network, optim, total_episodes, writer\n",
    "    network = CartPoleAgent().to(device)\n",
    "    optim = torch.optim.Adam(network.parameters())\n",
    "    total_episodes = 0\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "\n",
    "reset_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5de1ce73-c90c-46ec-92e3-148238e04b18",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7266d560",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agent(network, 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0107a43b-7476-4841-97ae-e55656dbd15d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EWMA():\n",
    "    \"Exponentially Weighted Moving Average\"\n",
    "    def __init__(self, alpha = 1/1000):\n",
    "        self.alpha = alpha\n",
    "        self.value = False\n",
    "\n",
    "    def add(self, value):\n",
    "        if not self.value:\n",
    "            self.value = value \n",
    "        else:\n",
    "            self.value = (1 - self.alpha) * self.value + self.alpha * value\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4edbc-8401-4809-b3eb-5171ef80bf7a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2385a703",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GAMMA=0.99\n",
    "ENTROPY_BETA=0.1\n",
    "\n",
    "def train_reinforce(steps):\n",
    "    global total_episodes\n",
    "    observation, info = env.reset(seed=42)\n",
    "    \n",
    "    total_reward = 0\n",
    "    episode_steps = 0\n",
    "    baseline = EWMA()\n",
    "    par = []\n",
    "    \n",
    "    def train(par):\n",
    "        # REINFORCE Update\n",
    "        # compute returns in backward order and compute loss\n",
    "        g_t = 0\n",
    "        loss = 0\n",
    "        for t in range(len(par)-1, -1, -1):\n",
    "            prob, action, reward = par[t]\n",
    "            g_t = reward + GAMMA * g_t\n",
    "\n",
    "            log_prob = torch.log(prob)\n",
    "            # L = - (G - baseline) ln \\pi(a)\n",
    "            loss += - (g_t - baseline.value) * log_prob[action]\n",
    "            ## L = entropy penalty\n",
    "            entropy = - (prob * log_prob).sum()         # H = - \\sum p_i log p_i\n",
    "            loss += - ENTROPY_BETA * entropy          # increase entropy \n",
    "        \n",
    "        if g_t == 0:\n",
    "            return \n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "    for step in range(steps):\n",
    "        action = network.action(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        par.append([network.action_probs, action, reward])\n",
    "        \n",
    "        total_reward += reward\n",
    "        episode_steps += 1\n",
    "        if terminated or truncated:\n",
    "            train(par)\n",
    "            par = []\n",
    "            observation, info = env.reset()\n",
    "            total_episodes += 1\n",
    "            baseline.add(episode_steps)\n",
    "            writer.add_scalar(\"Episode Length / Steps \", episode_steps, step)\n",
    "            writer.add_scalar(\"MA Reward/Episode\", baseline.value, total_episodes)\n",
    "            episode_steps = 0\n",
    "\n",
    "            if (total_episodes % 100 == 0):\n",
    "                print('Av. steps/ episode', baseline.value)\n",
    "    train(par)\n",
    "            \n",
    "    avg_reward = total_reward/total_episodes\n",
    "    writer.add_hparams({'entropy': ENTROPY_BETA, 'gamma': GAMMA, 'baseline': True, 'total_steps': steps}, {'avg_reward': avg_reward})\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce1f3f-3b64-405b-8dcb-6b76bbfb5876",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_network()\n",
    "train_reinforce(1000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10caa9-95bd-48fc-b9d4-b57b883869f2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 19.361409058274084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 13.658024962837741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 39.06096098048837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 37.17539607605714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 36.32582889474211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 25.279740533011555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 27.163509768156146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 16.18428461388143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. steps/ episode 16.70524518132659\n"
     ]
    }
   ],
   "source": [
    "for beta in [2/10, 1/10, 2/100, 1/100, 2/1000, 1/1000]:\n",
    "    ENTROPY_BETA = beta\n",
    "    reset_network()\n",
    "    train_reinforce(10_000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d6703812-389c-4bea-ad71-5616b7d2d973",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agent(network, 1_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/opt/homebrew/opt/python@3.11/bin/python3.11",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "name": "02 CartPole - 04.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
